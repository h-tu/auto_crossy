{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import keyboard\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm\n",
    "from PIL import ImageGrab, Image\n",
    "import matplotlib.pyplot as plt\n",
    "from pynput.keyboard import Key, Controller\n",
    "\n",
    "kb = Controller()\n",
    "lst = {0:'w', 1:'a', 2:'s', 3:'d', 4:'nop'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        # just run the init of parent class (nn.Module)\n",
    "        super().__init__() \n",
    "        # input is 1 image, 32 output channels, 5x5 kernel / window\n",
    "        self.conv1 = nn.Conv2d(1, 32, 5) \n",
    "        # input is 32, bc the first layer output 32. Then we say the output will be 64 channels, 5x5 kernel / window\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5) \n",
    "        self.conv3 = nn.Conv2d(64, 128, 5)\n",
    "\n",
    "        x = torch.randn(50,50).view(-1,1,50,50)\n",
    "        self._to_linear = None\n",
    "        self.convs(x)\n",
    "\n",
    "        self.fc1 = nn.Linear(self._to_linear, 512) #flattening.\n",
    "        self.fc2 = nn.Linear(512, 5) # 512 in, 2 out bc we're doing 2 classes (dog vs cat).\n",
    "\n",
    "    def convs(self, x):\n",
    "        # max pooling over 2x2\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)), (2, 2))\n",
    "\n",
    "        if self._to_linear is None:\n",
    "            self._to_linear = x[0].shape[0]*x[0].shape[1]*x[0].shape[2]\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convs(x)\n",
    "        x = x.view(-1, self._to_linear)  # .view is reshape ... this flattens X before \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x) # bc this is our output layer. No activation here.\n",
    "        return F.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load trained model\n",
    "\n",
    "PATH = \"Jul30_0940_model.pt\"\n",
    "\n",
    "model = Net()\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move(opt):\n",
    "    if opt < 4:\n",
    "        opt = lst[opt]\n",
    "        hit_key(opt)\n",
    "\n",
    "def hit_key(key):\n",
    "    kb.press(key)\n",
    "    time.sleep(0.1)\n",
    "    kb.release(key)\n",
    "\n",
    "# def roi(img, vertices):\n",
    "#     mask = np.zeros_like(img)\n",
    "#     cv2.fillPoly(mask, vertices, 255)\n",
    "#     masked = cv2.bitwise_and(img, mask)\n",
    "#     return masked\n",
    "\n",
    "def process_img(original_image):\n",
    "    processed_img = original_image\n",
    "    # Grey scale\n",
    "    processed_img = cv2.cvtColor(original_image, cv2.COLOR_BGR2GRAY)\n",
    "    # Zeropadding the image\n",
    "    processed_img = np.pad(processed_img, ((0,144),(0,0)), 'constant')\n",
    "    # ROI\n",
    "    # vertices = np.array([[440,37],[158,597], [425,664], [1001,665], [1229,247]], np.int32)\n",
    "    # processed_img = roi(processed_img, [vertices])\n",
    "    # Straighten the image\n",
    "    pts_src = np.array([[440,37], [1229,247], [158,597],[947,807]])\n",
    "    pts_dst = np.array([[0,0],[817, 0],[0,627],[817, 627]])\n",
    "    im_dst = np.zeros((627, 817, 3), np.uint8)\n",
    "    h, status = cv2.findHomography(pts_src, pts_dst)\n",
    "    processed_img = cv2.warpPerspective(processed_img, h, (im_dst.shape[1],im_dst.shape[0]))\n",
    "    \n",
    "    return processed_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3...\n",
      "2...\n",
      "1...\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print('{}...'.format(3-i))\n",
    "    time.sleep(1)\n",
    "\n",
    "while True:\n",
    "    screen =  np.array(ImageGrab.grab(bbox=(0,33,1280,699)))\n",
    "    new_screen = process_img(screen)\n",
    "    cv2.imshow('monitor', new_screen)\n",
    "    \n",
    "    tmp = cv2.resize(new_screen, (50, 50))\n",
    "    tmp = torch.Tensor(tmp)\n",
    "    output = model((tmp.view(-1, 1, 50, 50)))\n",
    "    try:\n",
    "        prediction = ((output == 1).nonzero().numpy()[0][1])\n",
    "    except Exception as e:\n",
    "        prediction = 4\n",
    "        pass\n",
    "    # print(prediction)\n",
    "    \n",
    "    move(prediction)\n",
    "    # time.sleep(0.1)\n",
    "    \n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            cv2.destroyAllWindows()\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
